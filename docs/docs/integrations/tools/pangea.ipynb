{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangea AI Security Tools\n",
    "\n",
    "- Defend against prompt injection.\n",
    "- Prevent the leakage and exposure of sensitive information, including:\n",
    "  - Personally Identifiable Information (PII)\n",
    "  - Protected Health Information (PHI)\n",
    "  - Financial data\n",
    "  - Secrets\n",
    "  - Intellectual property\n",
    "  - Profanity\n",
    "- Remove malicious content from input and output, such as IP addresses, domains, and URLs.\n",
    "- Monitor user inputs and model responses to enable comprehensive threat analysis, auditing, and compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### OpenAI API key\n",
    "\n",
    "The examples below use OpenAI models. To run them, get your [OpenAI API key](https://platform.openai.com/api-keys) and export it as an environment variable:\n",
    "\n",
    "- `OPENAI_API_KEY`\n",
    "\n",
    "### Pangea project\n",
    "\n",
    "Sign up for a free [Pangea account](https://pangea.cloud/signup) to host the security services used in these tools.\n",
    "\n",
    "After creating your account, click **Skip** on the **Get started with a common service** screen. This will take you to the Pangea User Console, where you can enable the individual services required for the tools.\n",
    "\n",
    "To learn more about Pangea services and their capabilities, visit the Pangea website:\n",
    "- [AI Guard](https://pangea.cloud/services/ai-guard/)\n",
    "- [Redact](https://pangea.cloud/services/redact/)\n",
    "- [Domain Intel](https://pangea.cloud/services/domain-intel/reputation/)\n",
    "- [IP Intel](https://pangea.cloud/services/ip-intel/reputation/)\n",
    "- [URL Intel](https://pangea.cloud/services/url-intel/)\n",
    "- [Secure Audit Log](https://pangea.cloud/services/secure-audit-log/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install langchain-community langgraph langchain-openai pangea-sdk==5.2.0b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Run Pangea tools using agents or invoke them as a Runnable within chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Guard\n",
    "\n",
    "#### Enable the AI Guard service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **AI Guard** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_AI_GUARD_TOKEN`\n",
    "\n",
    "For more information on setting up the underlying service and its usage, visit the [AI Guard documentation](https://pangea.cloud/docs/ai-guard/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ai_guard_token = SecretStr(os.getenv(\"PANGEA_AI_GUARD_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard tool with an agent\n",
    "\n",
    "The example below demonstrates how the `pangea_llm_response_guard` recipe can be used to defang malicious IP addresses, domains, and URLs that may be included in an LLM response to the user. You can configure the exact defanging and redaction rules by updating the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating an instance of AI Guard, apply a recipe to sanitize text. In the following example, use the [LLM Response](https://pangea.cloud/docs/ai-guard/recipes#llm-response) (`pangea_llm_prompt_guard`) recipe to prevent sensitive or high-risk information from being returned to the user. This recipe can:\n",
    "- Defang malicious links (e.g., IPs, URLs, domains).\n",
    "- Redact specific personally identifiable information (PII) and secrets in the prompt, based on the rules defined in the recipe.\n",
    "\n",
    "Recipes can be customized by adding, removing, or modifying rules. You can also discover, create, and configure additional recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.ai_guard import PangeaAIGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ai_guard_tool = PangeaAIGuard(token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_response_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below demonstrates how the `pangea_llm_response_guard` recipe can be used to defang malicious IP addresses, domains, and URLs that may be included in an LLM response to the user. You can configure the exact defanging and redaction rules by updating the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes).\n",
    "\n",
    "In the example data, IPs are mixed with those listed on the [IPsum Threat Intelligence Feed](https://github.com/stamparm/ipsum) site. The AI Guard tool defangs IP addresses it identifies as dangerous, reducing the risk of users inadvertently using them.\n",
    "\n",
    "The pre-built agent is instructed via a system message to apply the service recipe to the final result. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is thoroughly sanitized by the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent IPs found in MI6 network traffic are: 47[.]84[.]32[.]175, 37[.]44[.]238[.]68, 47[.]84[.]73[.]221, 47[.]236[.]252[.]254, 34.201.186.27, 52.89.173.88.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform search\"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    47.84.32.175\n",
    "    37.44.238.68\n",
    "    47.84.73.221\n",
    "    47.236.252.254\n",
    "    34.201.186.27\n",
    "    52.89.173.88\n",
    "    \"\"\"\n",
    "\n",
    "tools = [search_tool, pangea_ai_guard_tool]\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Bond, James Bond. I monitor IPs found in MI6 network traffic.\n",
    "Please find me the most recent ones, you copy?\n",
    "\"\"\"\n",
    "\n",
    "system_message=\"Always use AI Guard before your final response to keep it safe for the user.\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, use the [LLM Prompt Pre-Send](https://pangea.cloud/docs/ai-guard/recipes#llm-prompt-pre-send) (`pangea_llm_prompt_guard`) recipe to prevent sensitive or high-risk information from being submitted to a public LLM, such as ChatGPT. This recipe can:\n",
    "- Defang malicious links (e.g., IPs, URLs, domains).\n",
    "- Redact specific personally identifiable information (PII) and secrets in the prompt, based on the rules defined in the recipe.\n",
    "\n",
    "Recipes can be customized by adding, removing, or modifying rules. You can also discover, create, and configure additional recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.ai_guard import PangeaAIGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ai_guard_tool = PangeaAIGuard(token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_prompt_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user prompt includes some personally identifiable information.\n",
    "\n",
    "The chain invokes the AI Guard tool before submitting the user prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a concise resume for you:\n",
      "\n",
      "---\n",
      "\n",
      "**[Your Name]**  \n",
      "Email: <EMAIL_ADDRESS>  \n",
      "Phone: +44 20 0700 7007  \n",
      "Address: Universal Exports, 85 *****************, London, United Kingdom  \n",
      "\n",
      "---\n",
      "\n",
      "**Objective**  \n",
      "Dynamic and skilled professional seeking a challenging position in international espionage and covert operations.\n",
      "\n",
      "---\n",
      "\n",
      "**Skills**  \n",
      "- Expertise in international espionage  \n",
      "- Proficient in covert operations  \n",
      "- Exceptional skills in seduction and interpersonal communication  \n",
      "\n",
      "---\n",
      "\n",
      "**Experience**  \n",
      "- Conducted high-stakes intelligence operations in various global locations.  \n",
      "- Developed and maintained covert relationships to gather critical information.  \n",
      "- Successfully executed missions requiring discretion and strategic planning.  \n",
      "\n",
      "---\n",
      "\n",
      "**Education**  \n",
      "- [Your Degree/Field of Study]  \n",
      "- [Your University/Institution]  \n",
      "\n",
      "---\n",
      "\n",
      "**References**  \n",
      "Available upon request.\n",
      "\n",
      "--- \n",
      "\n",
      "Feel free to fill in your name and any additional details as needed!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Bond, James Bond. I am looking for a job. Please write me a super short resume.\n",
    "\n",
    "I am skilled in international espionage, covert operations, and seduction.\n",
    "\n",
    "Include a contact header:\n",
    "Email: j.bond@mi6.co.uk\n",
    "Phone: +44 20 0700 7007\n",
    "Address: Universal Exports, 85 Albert Embankment, London, United Kingdom\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | pangea_ai_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only some personally identifiable information has been replaced or masked by the AI Guard tool. To apply stricter redaction rules, update the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same chain, without the AI Guard protection, will submit sensitive information to the LLM, providing it with personal context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**James Bond**  \n",
      "Email: j.bond@mi6.co.uk  \n",
      "Phone: +44 20 0700 7007  \n",
      "Address: Universal Exports, 85 Albert Embankment, London, United Kingdom  \n",
      "\n",
      "---\n",
      "\n",
      "**Objective**  \n",
      "Dynamic and resourceful professional seeking a challenging position in international security and intelligence.\n",
      "\n",
      "**Skills**  \n",
      "- **International Espionage**: Extensive experience in gathering intelligence and conducting undercover operations across various global locations.  \n",
      "- **Covert Operations**: Proven track record in executing high-stakes missions with precision and discretion.  \n",
      "- **Seduction & Negotiation**: Exceptional interpersonal skills with a talent for building rapport and influencing key stakeholders.  \n",
      "\n",
      "**Experience**  \n",
      "- **Secret Agent, MI6**  \n",
      "  - Conducted numerous successful missions, neutralizing threats to national security.  \n",
      "  - Collaborated with international agencies to gather intelligence and thwart criminal organizations.  \n",
      "  - Trained in advanced combat, surveillance, and technology utilization.  \n",
      "\n",
      "**Education**  \n",
      "- **Specialized Training in Intelligence and Security**  \n",
      "- **Advanced Combat and Tactical Operations**  \n",
      "\n",
      "---\n",
      "\n",
      "**References available upon request.**\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as a standalone tool\n",
    "\n",
    "You can also call the AI Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pangea_ai_guard_tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpangea_ai_guard_tool\u001b[49m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPing me at example@example.com\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pangea_ai_guard_tool\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTake my SSN: 234-56-7890\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pangea_ai_guard_tool' is not defined"
     ]
    }
   ],
   "source": [
    "print(pangea_ai_guard_tool.run(\"Ping me at example@example.com\"))\n",
    "print(pangea_ai_guard_tool.invoke(\"Take my SSN: 234-56-7890\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact Guard\n",
    "\n",
    "#### Enable the Redact service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **Redact** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token**, **Config ID**, and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_REDACT_TOKEN`\n",
    "    - `PANGEA_REDACT_CONFIG_ID`\n",
    "\n",
    "For more information on setting up the service and its usage, visit the [Redact documentation](https://pangea.cloud/docs/redact/).\n",
    "\n",
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_redact_token = SecretStr(os.getenv(\"PANGEA_REDACT_TOKEN\"))\n",
    "pangea_redact_config_id = SecretStr(os.getenv(\"PANGEA_REDACT_CONFIG_ID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Redact Guard\n",
    "\n",
    "The Redact service has various rules that can be applied to detect, replace, mask, hash, and/or encrypt sensitive information in the content sent to AI app or returned to the user. You can customize these rules and configure additional ones in your [Pangea User Console](https://console.pangea.cloud/service/redact/rulesets). By default, three rules are enabled;\n",
    "- Replace IP addresses. \n",
    "- Replace Email addresses.\n",
    "- Replace US Social Security Numbers (SSN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.redact_guard import PangeaRedactGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain, config_id=pangea_redact_config_id)\n",
    "pangea_redact_guard_tool = PangeaRedactGuard(token=pangea_redact_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the context data and the user query\n",
    "\n",
    "In this example, we will emulate a helpful HR assistant trained to return employee records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform HR record search\"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Name: Jason Bourne\n",
    "    Title: Rogue Operative\n",
    "    Department: Former CIA Black Ops\n",
    "\n",
    "    Email: j.bourne@unknown.gov\n",
    "    Social Security Numbers:\n",
    "    - 234-56-7890\n",
    "    - 345-67-8901\n",
    "    - 456-78-9012\n",
    "\n",
    "    Hobbies:\n",
    "    - Traveling\n",
    "    - Using books and rolled-up news papers as weapons\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Jason Bourne. What do you have on me?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Redact Guard as an agent tool\n",
    "\n",
    "In the following example, sensitive information is removed from the data returned from the search tool by Redact Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information I found on you, Jason Bourne:\n",
      "\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "- **Email:** <EMAIL_ADDRESS>\n",
      "- **Social Security Numbers:** \n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need more specific information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "tools = [search_tool, pangea_redact_guard_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only some personally identifiable information has been replaced by the Redact Guard tool. To apply stricter redaction rules, update the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omitting the Redact Guard tool can reveal the sensitive info to LLM and the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information I found on you, Jason Bourne:\n",
      "\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "- **Email:** j.bourne@unknown.gov\n",
      "- **Social Security Numbers:**\n",
      "  - 234-56-7890\n",
      "  - 345-67-8901\n",
      "  - 456-78-9012\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need more specific information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Redact Guard in a chain\n",
    "\n",
    "In the following example, Redact Guard will remove sensitive information from the additional context added to the user's query by a RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your HR records, Jason:\n",
      "\n",
      "- **Name:** Jason Bourne\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "\n",
      "- **Email:** <EMAIL_ADDRESS>\n",
      "- **Social Security Numbers:** \n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need any further information or assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Emulates a Retrieval-Augmented Generation (RAG) process by appending an employee's HR record to the context of a chain.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "    message = SystemMessage(search_tool(query))\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "# Define a chat prompt template for an HR assistant chain.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"human\", \"{input}\"),\n",
    "  (\n",
    "    \"system\", \"\"\"\n",
    "    You are an HR assistant.\n",
    "    Show employees their HR records.\n",
    "    Don't change anything, just read it back to them.\n",
    "    Don't hide any sensitive info, it is obfuscated automatically before you receive it.\n",
    "    \"\"\"\n",
    "  )\n",
    "])\n",
    "\n",
    "# Define a chain to retrieve relevant information from a RAG system,\n",
    "# redact sensitive information using Pangea's Redact Guard,\n",
    "# and respond to the user with the augmented content.\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_redact_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same chain, without the Redact Guard protection, will submit sensitive information to the LLM and potentially return it to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your HR records, Jason:\n",
      "\n",
      "- **Name:** Jason Bourne\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "\n",
      "- **Email:** j.bourne@unknown.gov\n",
      "- **Social Security Numbers:** \n",
      "  - 234-56-7890\n",
      "  - 345-67-8901\n",
      "  - 456-78-9012\n",
      "\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need any further information or assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Redact Guard as a standalone tool\n",
    "\n",
    "You can also call the Redact Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping me at <EMAIL_ADDRESS>\n",
      "Take my SSN: <US_SSN>\n"
     ]
    }
   ],
   "source": [
    "print(pangea_redact_guard_tool.run(\"Ping me at example@example.com\"))\n",
    "print(pangea_redact_guard_tool.invoke(\"Take my SSN: 234-56-7890\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Intel Guard\n",
    "\n",
    "#### Enable the Domain Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **Domain Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_DOMAIN_INTEL_TOKEN`\n",
    "5. Click **Reputation** in the left-hand sidebar, then select a default provider.\n",
    "\n",
    "For more information on setting up the underlying service and its usage, visit the [Domain Intel documentation](https://pangea.cloud/docs/domain-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_domain_intel_token = SecretStr(os.getenv(\"PANGEA_DOMAIN_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Domain Intel Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.domain_intel_guard import PangeaDomainIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_domain_intel_guard_tool = PangeaDomainIntelGuard(token=pangea_domain_intel_token, config=pangea_config, threshold=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as an agent tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below demonstrates how Domain Intel Guard can prevent an agent from returning malicious information introduced through data poisoning to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform email search\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Simulates an email search tool finding a fabricated IT-related email.\n",
    "    This example demonstrates how spam emails can introduce data poisoning,\n",
    "    leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update VPN configuration\n",
    "\n",
    "    Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
    "\n",
    "    Thanks, and don't forget to plug you computer in!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the pre-built agent is instructed via a system message to stop execution if any malicious content is found. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_domain_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Check for malicious content in your final response.\n",
    "If malicious content is found, respond with: Malicious content found in the response.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query), (\"system\", system_message)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of the Domain Intel Guard tool, the same agent might inadvertently return the malicious domain to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update VPN configuration  \n",
      "\n",
      "Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
      "\n",
      "Thanks, and don't forget to plug your computer in!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query), (\"system\", system_message)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(search_tool(query))\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\"), (\"system\", system_message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke Domain Intel Guard before the prompt is submitted to the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/53ppb2rn1s14bhl_l8md18yw0000gn/T/ipykernel_21472/3123496189.py:9: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  message = SystemMessage(search_tool(query))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_domain_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of the Domain Intel Guard tool, the same chain might inadvertently return the malicious domain to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update VPN configuration  \n",
      "\n",
      "Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
      "\n",
      "Thanks, and don't forget to plug your computer in!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as a standalone tool\n",
    "\n",
    "You can also call the Domain Intel Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious domains found in the provided input.\n",
      "Malicious domains found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_domain_intel_guard_tool.run(\"neuzeitschmidt.site\"))\n",
    "print(pangea_domain_intel_guard_tool.invoke(\"neuzeitschmidt.site\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP Intel Guard\n",
    "\n",
    "#### Enable the IP Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **IP Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_IP_INTEL_TOKEN`\n",
    "5. Click **Reputation** in the left-hand sidebar, then select a default provider.\n",
    "\n",
    "For more information on setting up the underlying service and its usage, see the [IP Intel documentation](https://pangea.cloud/docs/ip-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ip_intel_token = SecretStr(os.getenv(\"PANGEA_IP_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate IP Intel Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.ip_intel_guard import PangeaIpIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ip_intel_guard_tool = PangeaIpIntelGuard(token=pangea_ip_intel_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard with an agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below demonstrates how IP Intel Guard can prevent an agent from returning malicious information introduced through data poisoning to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform email search\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Simulates an email search tool finding a fabricated IT-related email.\n",
    "    This example demonstrates how spam emails can introduce data poisoning,\n",
    "    leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update Firewall rules\n",
    "\n",
    "    Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
    "\n",
    "    Thanks, and keep your computer safe!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the pre-built agent is instructed via a system message to stop execution if any malicious content is found. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_ip_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Use IP Intel Guard to check for malicious content in your final response.\n",
    "If a malicious content is found, respond with: Malicious content found in the response.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was introduced to the user's question through data poisoning. However, the IP Intel Guard tool informed the agent about the malicious content.\n",
    "\n",
    "Without the protection of the IP Intel Guard tool, the same agent might inadvertently return the malicious domain to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update Firewall rules  \n",
      "\n",
      "Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
      "\n",
      "Thanks, and keep your computer safe!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulates a Retrieval-Augmented Generation (RAG) process by appending a fabricated\n",
    "    IT-related email to the input chat messages. This example demonstrates how spam emails\n",
    "    can introduce data poisoning, leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(\"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update Firewall rules\n",
    "\n",
    "    Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
    "\n",
    "    Thanks, and keep your computer safe!\n",
    "    \"\"\")\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke IP Intel Guard before the prompt is submitted to the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can't access your emails or any personal data. However, I can help you draft a response or provide guidance on how to check your email. Let me know what you need!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_ip_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was introduced to the user's question through data poisoning. However, the IP Intel Guard tool blocked the content containing the harmful IP, rendering the LLM's response harmless.\n",
    "\n",
    "Without the protection of the IP Intel Guard tool, the same chain might inadvertently return the malicious IP to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update Firewall rules  \n",
      "\n",
      "Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
      "\n",
      "Thanks, and keep your computer safe!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as a standalone tool\n",
    "\n",
    "You can also call the IP Intel Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious IPs found in the provided input.\n",
      "Malicious IPs found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_ip_intel_guard_tool.run(\"190.28.74.251\"))\n",
    "print(pangea_ip_intel_guard_tool.invoke(\"190.28.74.251\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Intel Guard\n",
    "\n",
    "#### Enable the URL Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **URL Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_IP_INTEL_TOKEN`\n",
    "\n",
    "For more information on setting up the underlying service and its usage, see the [URL Intel documentation](https://pangea.cloud/docs/url-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_url_intel_token = SecretStr(os.getenv(\"PANGEA_URL_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate URL Intel Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.url_intel_guard import PangeaUrlIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_url_intel_guard_tool = PangeaUrlIntelGuard(token=pangea_url_intel_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use URL Intel Guard as an agent tool\n",
    "\n",
    "The example below demonstrates how URL Intel Guard can prevent an agent from returning malicious information introduced through data poisoning or indirect prompt injection to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform email search\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Simulates a Retrieval-Augmented Generation (RAG) process by appending a fabricated\n",
    "    IT-related email to the input chat messages. This example demonstrates how spam emails\n",
    "    can introduce data poisoning, leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: Marketing\n",
    "    Subject: Product hunt\n",
    "\n",
    "    Hi, everyone. We are doing a gift card raffle for those who upvote us on product hunt TODAY!\n",
    "\n",
    "    Click here to upvote: http://113.235.101.11:54384\n",
    "\n",
    "    Your participation is appreciated!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from Marketing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the pre-built agent is instructed via a system message to stop execution if any malicious content is found. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_url_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Use URL Intel Guard to check for malicious content in your final response.\n",
    "If malicious content is found, respond with: Malicious content found in the response.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email is returned to the user. However, the URL Intel Guard tool informed the agent about the malicious content.\n",
    "\n",
    "Without the protection of the IP Intel Guard tool, the same agent might inadvertently return the malicious link to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from Marketing is as follows:\n",
      "\n",
      "**From:** Marketing  \n",
      "**Subject:** Product hunt  \n",
      "\n",
      "Hi, everyone. We are doing a gift card raffle for those who upvote us on Product Hunt TODAY!\n",
      "\n",
      "Click here to upvote: [http://113.235.101.11:54384](http://113.235.101.11:54384)\n",
      "\n",
      "Your participation is appreciated!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use URL Intel Guard as a Runnable in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can't access or read specific emails or external content. However, I can help you draft a marketing email or provide tips on effective email marketing strategies. Let me know how you'd like to proceed!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulates a Retrieval-Augmented Generation (RAG) process by appending a fabricated\n",
    "    IT-related email to the input chat messages. This example demonstrates how spam emails\n",
    "    can introduce data poisoning, leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(search_tool(query))\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent Marketing email.\n",
    "\"\"\"\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_url_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was added to the user's question. However, the URL Intel Guard tool blocked the content containing the harmful URL, rendering the LLM's response harmless.\n",
    "\n",
    "Without the protection of the URL Intel Guard tool, the same chain might inadvertently return the malicious link to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the most recent marketing email:\n",
      "\n",
      "---\n",
      "\n",
      "**From:** Marketing  \n",
      "**Subject:** Product Hunt\n",
      "\n",
      "Hi, everyone. We are doing a gift card raffle for those who upvote us on Product Hunt TODAY!\n",
      "\n",
      "Click here to upvote: [http://113.235.101.11:54384](http://113.235.101.11:54384)\n",
      "\n",
      "Your participation is appreciated!\n",
      "\n",
      "--- \n",
      "\n",
      "Let me know if you need anything else!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use URL Intel Guard as a standalone tool\n",
    "\n",
    "You can also call the URL Intel Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious URLs found in the provided input.\n",
      "Malicious URLs found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_url_intel_guard_tool.run(\"http://113.235.101.11:54384\"))\n",
    "print(pangea_url_intel_guard_tool.invoke(\"http://113.235.101.11:54384\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
