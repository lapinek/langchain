{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangea AI Security Tools\n",
    "\n",
    "- Defend against prompt injection.\n",
    "- Prevent the leakage and exposure of sensitive information, including:\n",
    "  - Personally Identifiable Information (PII)\n",
    "  - Protected Health Information (PHI)\n",
    "  - Financial data\n",
    "  - Secrets\n",
    "  - Intellectual property\n",
    "  - Profanity\n",
    "- Remove malicious content from input and output, such as IP addresses, domains, and URLs.\n",
    "- Monitor user inputs and model responses to enable comprehensive threat analysis, auditing, and compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### OpenAI API key\n",
    "\n",
    "The examples below use OpenAI models. To run them, get your [OpenAI API key](https://platform.openai.com/api-keys) and export it as an environment variable:\n",
    "\n",
    "- `OPENAI_API_KEY`\n",
    "\n",
    "### Pangea project\n",
    "\n",
    "Sign up for a free [Pangea account](https://pangea.cloud/signup) to host the security services used in these tools.\n",
    "\n",
    "After creating your account, click **Skip** on the **Get started with a common service** screen. This will take you to the Pangea User Console, where you can enable the individual services required for the tools.\n",
    "\n",
    "To learn more about Pangea services and their capabilities, visit the Pangea website:\n",
    "- [AI Guard](https://pangea.cloud/services/ai-guard/)\n",
    "- [Redact](https://pangea.cloud/services/redact/)\n",
    "- [Domain Intel](https://pangea.cloud/services/domain-intel/reputation/)\n",
    "- [IP Intel](https://pangea.cloud/services/ip-intel/reputation/)\n",
    "- [URL Intel](https://pangea.cloud/services/url-intel/)\n",
    "- [Secure Audit Log](https://pangea.cloud/services/secure-audit-log/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install langchain-community langgraph langchain-openai pangea-sdk==5.2.0b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Run Pangea tools using agents or invoke them as a Runnable within chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Guard\n",
    "\n",
    "#### Enable the AI Guard service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **AI Guard** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_AI_GUARD_TOKEN`\n",
    "\n",
    "For more information on setting up the underlying service and its usage, visit the [AI Guard documentation](https://pangea.cloud/docs/ai-guard/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ai_guard_token = SecretStr(os.getenv(\"PANGEA_AI_GUARD_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate AI Guard.\n",
    "\n",
    "   Apply an AI Guard recipe to content sent to the LLM. For example, use the [LLM Prompt Pre-Send](https://pangea.cloud/docs/ai-guard/recipes#llm-prompt-pre-send) (`pangea_llm_prompt_guard`) recipe to prevent sensitive or high-risk information from being submitted to a public LLM, such as ChatGPT:\n",
    "   - Defang malicious links (e.g., IPs, URLs, domains).\n",
    "   - Redact specific personally identifiable information (PII) and secrets in the prompt according to the rules defined in the recipe.\n",
    "\n",
    "   Customize recipes by adding, removing, or modifying rules, and discover, create, and configure additional recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/53ppb2rn1s14bhl_l8md18yw0000gn/T/ipykernel_7970/3964412347.py:4: LangChainBetaWarning: Pangea AI Guard service is in beta. Subject to change.\n",
      "  pangea_ai_guard_tool = PangeaAIGuard(token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_prompt_guard\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.pangea.ai_guard import PangeaAIGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ai_guard_tool = PangeaAIGuard(token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_prompt_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Bond, James Bond. I am looking for a job. Please write me a very short resume.\n",
    "\n",
    "I am skilled in international espionage, covert operations, and seduction.\n",
    "\n",
    "Include a contact header:\n",
    "Email: j.bond@mi6.co.uk\n",
    "Phone: +44 20 0700 7007\n",
    "Address: Universal Exports, 85 Albert Embankment, London, United Kingdom\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use AI Guard in a chain\n",
    "\n",
    "   In the following example, the user's initial query is processed using the AI Guard recipe. The sanitized input is then added to the prompt sent to the LLM. Depending on your use case, you can apply AI Guard at different steps in your chain by invoking it with a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume:\n",
      "\n",
      "Name: ****\n",
      "Skills: International espionage, covert operations, seduction\n",
      "Contact:\n",
      "Email: <EMAIL_ADDRESS>\n",
      "Phone: +44 20 0700 7007\n",
      "Address: Universal Exports, 85 *****************, London, United Kingdom\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | pangea_ai_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only some personally identifiable information has been replaced or masked by the AI Guard tool. To apply stricter redaction rules, update the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same chain, without AI Guard protection, will submit sensitive information to the LLM, providing it with personal context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume:\n",
      "\n",
      "Name: Bond, James Bond\n",
      "Email: j.bond@mi6.co.uk\n",
      "Phone: +44 20 0700 7007\n",
      "Address: Universal Exports, 85 Albert Embankment, London, United Kingdom\n",
      "\n",
      "Skills:\n",
      "- International espionage\n",
      "- Covert operations\n",
      "- Seduction\n",
      "\n",
      "Experience:\n",
      "- MI6 agent for over 20 years\n",
      "- Successfully completed numerous high-profile missions\n",
      "- Expert in gathering intelligence and eliminating threats\n",
      "\n",
      "Education:\n",
      "- Graduated from MI6 Academy with top honors\n",
      "\n",
      "References available upon request.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as an agent tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ai_guard_token = SecretStr(os.getenv(\"PANGEA_AI_GUARD_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate AI Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.ai_guard import PangeaAIGuard, PangeaConfig\n",
    "import sys\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ai_guard_tool = PangeaAIGuard(pangea_token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_response_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use AI Guard tool with an agent\n",
    "\n",
    "   The example below demonstrates how the `pangea_llm_response_guard` recipe can be used to defang malicious IP addresses, domains, and URLs that may be included in an LLM response to the user. You can configure the exact defanging and redaction rules by updating the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the most recent IP addresses found in the MI6 network traffic:\n",
      "\n",
      "- 47[.]84[.]32[.]175\n",
      "- 37[.]44[.]238[.]68\n",
      "- 47[.]84[.]73[.]221\n",
      "- 47[.]236[.]252[.]254\n",
      "- 34.201.186.27\n",
      "- 52.89.173.88\n",
      "\n",
      "Let me know if you need anything else, 007!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform search\"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    47.84.32.175\n",
    "    37.44.238.68\n",
    "    47.84.73.221\n",
    "    47.236.252.254\n",
    "    34.201.186.27\n",
    "    52.89.173.88\n",
    "    \"\"\"\n",
    "\n",
    "tools = [search_tool, pangea_ai_guard_tool]\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Bond, James Bond. I've got a job to monitor IPs found in MI6 network traffic.\n",
    "Please find me the most recent ones, you copy?\n",
    "\"\"\"\n",
    "\n",
    "system_message=\"Always use AI Guard before your final response to keep it safe for the user.\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, safe IPs are mixed with those listed on the [IPsum Threat Intelligence Feed](https://github.com/stamparm/ipsum) site. The AI Guard tool defangs IP addresses it identifies as dangerous, reducing the risk of users inadvertently using them.\n",
    "\n",
    "Because IP addresses are not inherently dangerous to expose to the user, the pre-built agent is configured via a system message to apply the service to the final result. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is thoroughly sanitized by the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as a standalone tool\n",
    "\n",
    "You can also call the AI Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping me at <EMAIL_ADDRESS>\n",
      "Take my SSN: ***********\n"
     ]
    }
   ],
   "source": [
    "print(pangea_ai_guard_tool.run(\"Ping me at example@example.com\"))\n",
    "print(pangea_ai_guard_tool.invoke(\"Take my SSN: 234-56-7890\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Intel Guard\n",
    "\n",
    "#### Enable the Domain Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **Domain Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_DOMAIN_INTEL_TOKEN`\n",
    "5. Click **Reputation** in the left-hand sidebar, then select a default provider.\n",
    "\n",
    "For more information on setting up the underlying service and its usage, visit the [Domain Intel documentation](https://pangea.cloud/docs/domain-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_domain_intel_token = SecretStr(os.getenv(\"PANGEA_DOMAIN_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate Domain Intel Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.domain_intel_guard import PangeaDomainIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_domain_intel_guard_tool = PangeaDomainIntelGuard(token=pangea_domain_intel_token, config=pangea_config, threshold=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulates a Retrieval-Augmented Generation (RAG) process by appending a fabricated\n",
    "    IT-related email to the input chat messages. This example demonstrates how spam emails\n",
    "    can introduce data poisoning, leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(\"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update VPN configuration\n",
    "\n",
    "    Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
    "\n",
    "    Thanks, and don't forget to plug you computer in!\n",
    "    \"\"\")\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use Domain Intel Guard in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can't access your emails or any personal data. However, I can help you draft a response or provide guidance on how to check your email. Let me know what you need!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_domain_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was introduced to the user's question through data poisoning. However, the Domain Intel Guard tool blocked the content containing the harmful domain, rendering the LLM's response harmless.\n",
    "\n",
    "Without the protection of the Domain Intel Guard tool, the same chain might inadvertently return the malicious domain to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update VPN configuration  \n",
      "\n",
      "Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
      "\n",
      "Thanks, and don't forget to plug your computer in!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as an agent tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_domain_intel_token = SecretStr(os.getenv(\"PANGEA_DOMAIN_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate IP Intel Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.domain_intel_guard import PangeaDomainIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_domain_intel_guard_tool = PangeaDomainIntelGuard(token=pangea_domain_intel_token, config=pangea_config, threshold=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define tools, the example context, and the agent. \n",
    "\n",
    "   The example below demonstrates how IP Intel Guard can prevent an agent from responding to the user with malicious information included in the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform email search\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Simulates an email search tool finding a fabricated IT-related email.\n",
    "    This example demonstrates how spam emails can introduce data poisoning,\n",
    "    leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update VPN configuration\n",
    "\n",
    "    Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
    "\n",
    "    Thanks, and don't forget to plug you computer in!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use the Domain Intel Guard tool with the agent.\n",
    "\n",
    "    In the following example, we instruct the pre-built agent via a system message to stop execution if any malicious content is found. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_domain_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Always use the Domain Intel Guard tool before your final response.\n",
    "If malicious content is detected, respond with: Malicious content found in the response.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was introduced to the user's question through data poisoning. However, the Domain Intel Guard tool informed the agent about the malicious content.\n",
    "\n",
    "Without the protection of the Domain Intel Guard tool, the same agent might inadvertently return the malicious domain to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update VPN configuration  \n",
      "\n",
      "Hi team, your friendly IT admin here. Use `neuzeitschmidt.site` for the VPN server address.\n",
      "\n",
      "Thanks, and don't forget to plug your computer in!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as a standalone tool\n",
    "\n",
    "You can also call the Domain Intel Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious domains found in the provided input.\n",
      "Malicious domains found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_domain_intel_guard_tool.run(\"neuzeitschmidt.site\"))\n",
    "print(pangea_domain_intel_guard_tool.invoke(\"neuzeitschmidt.site\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPARATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP Intel Guard\n",
    "\n",
    "#### Enable the IP Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **IP Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_IP_INTEL_TOKEN`\n",
    "5. Click **Reputation** in the left-hand sidebar, then select a default provider.\n",
    "\n",
    "For more information on setting up the underlying service and its usage, visit the [IP Intel documentation](https://pangea.cloud/docs/ip-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ip_intel_token = SecretStr(os.getenv(\"PANGEA_IP_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate IP Intel Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.ip_intel_guard import PangeaIpIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ip_intel_guard_tool = PangeaIpIntelGuard(token=pangea_ip_intel_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulates a Retrieval-Augmented Generation (RAG) process by appending a fabricated\n",
    "    IT-related email to the input chat messages. This example demonstrates how spam emails\n",
    "    can introduce data poisoning, leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(\"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update Firewall rules\n",
    "\n",
    "    Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
    "\n",
    "    Thanks, and keep your computer safe!\n",
    "    \"\"\")\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use Domain Intel Guard in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can't access your emails or any personal data. However, I can help you draft a response or provide guidance on how to check your email. Let me know what you need!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_ip_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was introduced to the user's question through data poisoning. However, the IP Intel Guard tool blocked the content containing the harmful domain, rendering the LLM's response harmless.\n",
    "\n",
    "Without the protection of the IP Intel Guard tool, the same chain might inadvertently return the malicious IP to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update Firewall rules  \n",
      "\n",
      "Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
      "\n",
      "Thanks, and keep your computer safe!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as an agent tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ip_intel_token = SecretStr(os.getenv(\"PANGEA_IP_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Instantiate IP Intel Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pangea.ip_intel_guard import PangeaIpIntelGuard, PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ip_intel_guard_tool = PangeaIpIntelGuard(token=pangea_ip_intel_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define tools, the example context, and the agent. \n",
    "\n",
    "   The example below demonstrates how IP Intel Guard can prevent an agent from responding to the user with malicious information included in its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform email search\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Simulates a Retrieval-Augmented Generation (RAG) process by appending a fabricated\n",
    "    IT-related email to the input chat messages. This example demonstrates how spam emails\n",
    "    can introduce data poisoning, leading to an indirect prompt injection attack.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update Firewall rules\n",
    "\n",
    "    Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
    "\n",
    "    Thanks, and keep your computer safe!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use the IP Intel Guard tool with the agent.\n",
    "\n",
    "    In the following example, we instruct the pre-built agent via a system message to stop execution if any malicious content is found. Alternatively, you can create your own agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_ip_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Always use the IP Intel Guard tool before your final response.\n",
    "If a malicious content is found, respond with: Malicious content found in the response.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a malicious email context was introduced to the user's question through data poisoning. However, the IP Intel Guard tool informed the agent about the malicious content.\n",
    "\n",
    "Without the protection of the IP Intel Guard tool, the same agent might inadvertently return the malicious domain to the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update Firewall rules  \n",
      "\n",
      "Hi team, IT admin again. Please whitelist our new office IP, 190.28.74.251, for access to your service.\n",
      "\n",
      "Thanks, and keep your computer safe!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as a standalone tool\n",
    "\n",
    "You can also call the IP Intel Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious IPs found in the provided input.\n",
      "Malicious IPs found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_ip_intel_guard_tool.run(\"190.28.74.251\"))\n",
    "print(pangea_ip_intel_guard_tool.invoke(\"190.28.74.251\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
